# HOT template
# 
heat_template_version: 2014-10-16 

description: >
  start a distributed setup with loadbalancer, appserver, 
  elasticsearch servers, dbmaster an dbslaves.
  You can start this heat stack with 
  ''heat stack-create -f multiserver-stack.yaml -e multiserver-env.yaml -P key_name=<yourRealKeyName> -P deploy_key="$(cat ~/.ssh/cloud_deploykey)" <myFancyStackName>''
  This example has two private networks and two public/floating IPs (one for your jumphost
  one for the loadbalancer).

parameters:
  key_name:
    default: replacemewitharealkey
    type: string
    description: Name of keypair to assign to servers
  image:
    type: string
    default: Ubuntu 14.04 sys11-cloudimg amd64
    description: Default image to use for servers
  number_appservers:
    type: string
    description: Flavor appserver
    default: 4
  number_elasticsearch:
    type: string
    description: Flavor appserver
    default: 2
  number_dbslaves:
    type: string
    description: Flavor appserver
    default: 2
  flavor_admin:
    type: string
    default: m1.tiny
    description: Flavor appserver
  flavor_app:
    type: string
    default: m1.tiny
    description: Flavor appserver
  flavor_elasticsearch:
    type: string
    default: m1.tiny
    description: Flavor appserver
  flavor_dbslaves:
    type: string
    default: m1.tiny
    description: Flavor appserver
  flavor_dbserver:
    type: string
    default: m1.small
    description: Flavor dbserver
  flavor_loadbalancer:
    type: string
    default: m1.tiny
    description: Flavor loadbalancer 
  public_net_id:
    type: string
    description: >
      ID of public network for which floating IP addresses will be allocated
  deploy_key:
    type: string
    hidden: True
    description: SSH private key required to access bootstrap repository
  kickstart_repository:
    type: string
    description: Git repository containing node kickstart scripts
    default: git@gitlab.syseleven.de:openstack/openstack-scripts.git
  kickstart_branch:
    type: string
    description: Git branch to use in kickstart scripts repository
    default: master
  kickstart_directory:
    type: string
    description: directory where my bootstrapping files go 
    default: /tmp 
  init_script:
    type: string
    description: Script to run for node initialization
    default: |
      #!/bin/bash
      # 2014, s.andres@syseleven.de
      # 2015, j.peschke@syseleven.de
  
      exec > /var/log/init_script.log 2>&1
      set -x

      export repo=kickstart_repository 
      export branch=kickstart_branch
      export kickstart_dir=kickstart_directory

      export varsThatYouNeed=exampleVar 

      deploykeypath=/root/.ssh/id_deploy

      setup_git() {
        aptitude update &&
        aptitude install -y git &&

        mkdir -p /root/.ssh/
        touch $deploykeypath
        chmod 600 $deploykeypath
        cat > $deploykeypath <<EOF
      deploy_key
      EOF

        echo "${deploykeypath}" | ssh-keygen -y > "${deploykeypath}.pub"

        cat > /root/.ssh/config <<EOF
        Host gitlab.syseleven.de
        IdentityFile $deploykeypath
        UserKnownHostsFile=/dev/null
        StrictHostKeyChecking=no
      EOF

        git clone $repo $kickstart_dir &&
        (cd $kickstart_dir ; git checkout $branch) 
      }

      setup_git &&
      $kickstart_dir/myServerProvisioningScript

resources:

  allow_https:
    type: OS::Neutron::SecurityGroup
    properties:
      description: allow incoming https traffic from anywhere.
      name: https incoming
      rules: [{direction: ingress, remote_ip_prefix: 0.0.0.0/0, port_range_min: 443, port_range_max: 443, protocol: tcp} ]

  allow_http:
    type: OS::Neutron::SecurityGroup
    properties:
      description: allow incoming http traffic from anywhere.
      name: http incoming
      rules: [{direction: ingress, remote_ip_prefix: 0.0.0.0/0, port_range_min: 80, port_range_max: 80, protocol: tcp} ]

  allow_ssh:
    type: OS::Neutron::SecurityGroup
    properties:
      description: allow incoming ssh traffic from anywhere.
      name: ssh incoming
      rules: [{direction: ingress, remote_ip_prefix: 0.0.0.0/0, port_range_min: 22, port_range_max: 22, protocol: tcp} ]

  mgm_router:
    type: OS::Neutron::Router
    properties:
      external_gateway_info: {"network": { get_param: public_net_id }, "enable_snat": true}

  router_subnet_connect:
    type: OS::Neutron::RouterInterface
    depends_on: [ mgm_subnet, mgm_router ]
    properties:
      router_id: { get_resource: mgm_router }
      subnet: { get_resource: mgm_subnet }

  app_net:
    depends_on: mgm_net
    type: OS::Neutron::Net
    properties: 
      name: application_network 

  app_subnet:
    type: OS::Neutron::Subnet
    properties:
      name: application_subnet
      dns_nameservers:
        - 37.123.105.116
        - 37.123.105.117
      network_id: {get_resource: app_net}
      ip_version: 4
      cidr: 10.0.0.0/24
      allocation_pools:
      - {start: 10.0.0.10, end: 10.0.0.240}

  mgm_net:
    type: OS::Neutron::Net
    properties: 
      name: management_network 

  mgm_subnet:
    type: OS::Neutron::Subnet
    properties:
      name: management_subnet
      dns_nameservers:
        - 37.123.105.116
        - 37.123.105.117
      network_id: {get_resource: mgm_net}
      ip_version: 4
      gateway_ip : 10.0.1.1
      cidr: 10.0.1.0/24
      allocation_pools:
      - {start: 10.0.1.10, end: 10.0.1.240}

  ### Loadbalancer Node ###
  #######################
  loadbalancer:
    type: OS::Nova::Server
    properties:
      name: loadbalancer
      image: { get_param: image }
      flavor: { get_param: flavor_loadbalancer }
      config_drive: 'true'
      key_name: { get_param: key_name }
      networks:
        - port: { get_resource: loadbalancer_mgm_port }
        - port: { get_resource: loadbalancer_app_port }
      metadata:
        stack_name: { get_param: 'OS::stack_name' }
        floating_ip: { get_attr: [ loadbalancer_floating_ip, floating_ip_address ] }
      user_data_format: RAW  # Leave this in. Otherwise the ssh key specified in key_name won't get deployed. I'll buy you a beer if you tell me why that happens.
      user_data:
        str_replace:
          template: { get_param: init_script}
          params:
            deploy_key: { get_param: deploy_key }
            kickstart_repository: { get_param: kickstart_repository }
            kickstart_branch: { get_param: kickstart_branch }
            kickstart_directory: { get_param: kickstart_directory }

  loadbalancer_mgm_port:
    depends_on: mgm_net
    type: OS::Neutron::Port
    properties:
      network_id: { get_resource: mgm_net }

  loadbalancer_app_port:
    depends_on: app_net
    type: OS::Neutron::Port
    properties:
      network_id: { get_resource: app_net }

  loadbalancer_floating_ip:
    type: OS::Neutron::FloatingIP
    properties:
      floating_network_id: { get_param: public_net_id }
      port_id: { get_resource: loadbalancer_mgm_port }

  ### Adminserver Node ###
  #######################
  adminserver:
    type: OS::Nova::Server
    properties:
      name: adminserver
      image: { get_param: image }
      flavor: { get_param: flavor_admin }
      config_drive: 'true'
      key_name: { get_param: key_name }
      networks:
        - port: { get_resource: adminserver_mgm_port }
        - port: { get_resource: adminserver_app_port }
      metadata:
        stack_name: { get_param: 'OS::stack_name' }
        floating_ip: { get_attr: [ adminserver_floating_ip, floating_ip_address ] }
      user_data_format: RAW  # Leave this in. Otherwise the ssh key specified in key_name won't get deployed. I'll buy you a beer if you tell me why that happens.
      user_data:
        str_replace:
          template: { get_param: init_script}
          params:
            deploy_key: { get_param: deploy_key }
            kickstart_repository: { get_param: kickstart_repository }
            kickstart_branch: { get_param: kickstart_branch }
            kickstart_directory: { get_param: kickstart_directory }

  adminserver_mgm_port:
    depends_on: mgm_net
    type: OS::Neutron::Port
    properties:
      network_id: { get_resource: mgm_net }

  adminserver_app_port:
    depends_on: app_net
    type: OS::Neutron::Port
    properties:
      network_id: { get_resource: app_net }

  adminserver_floating_ip:
    type: OS::Neutron::FloatingIP
    properties:
      floating_network_id: { get_param: public_net_id }
      port_id: { get_resource: adminserver_mgm_port }

  ### Appserver Nodes as resource group ###
  #######################
  appserver_group:
    type: OS::Heat::ResourceGroup
    depends_on: [ app_subnet, mgm_subnet ]
    properties:
      count: { get_param: number_appservers } 
      resource_def: 
        type: appserver.yaml
        properties:
          app_net: { get_resource: app_net }
          mgm_net: { get_resource: mgm_net }
          server_name: app%index%
          key_name: { get_param: key_name }
          image: { get_param: image }
          flavor: {get_param: flavor_app }
          deploy_key: {get_param: deploy_key }
          init_script: {get_param: init_script }
          kickstart_repository: { get_param: kickstart_repository }
          kickstart_branch: { get_param: kickstart_branch }
          kickstart_directory: { get_param: kickstart_directory }
          
  ### Elasticsearch Nodes as resource group ###
  #######################
  elasticsearch_group:
    type: OS::Heat::ResourceGroup
    depends_on: [ mgm_subnet ]
    properties:
      count: { get_param: number_elasticsearch } 
      resource_def: 
        type: elasticsearch.yaml
        properties:
          mgm_net: { get_resource: mgm_net }
          server_name: elasticsearch%index%
          key_name: { get_param: key_name }
          image: { get_param: image }
          flavor: {get_param: flavor_elasticsearch }
          deploy_key: {get_param: deploy_key }
          init_script: {get_param: init_script }
          kickstart_repository: {get_param: kickstart_repository }
          kickstart_branch: {get_param: kickstart_branch }
          kickstart_directory: { get_param: kickstart_directory }
          
  ### DB-Slaves Nodes as resource group ###
  #######################
  dbslave_group:
    type: OS::Heat::ResourceGroup
    depends_on: [ mgm_subnet ]
    properties:
      count: { get_param: number_dbslaves } 
      resource_def: 
        type: dbslaves.yaml
        properties:
          mgm_net: { get_resource: mgm_net }
          server_name: dbslave%index%
          key_name: { get_param: key_name }
          image: { get_param: image }
          flavor: {get_param: flavor_dbslaves }
          deploy_key: {get_param: deploy_key }
          init_script: {get_param: init_script }
          kickstart_repository: {get_param: kickstart_repository }
          kickstart_branch: {get_param: kickstart_branch }
          kickstart_directory: { get_param: kickstart_directory }
       
  ### Database Master Node ###
  #######################
  dbserver:
    type: OS::Nova::Server
    properties:
      name: dbmaster
      image: { get_param: image }
      flavor: { get_param: flavor_dbserver }
      config_drive: 'true'
      key_name: { get_param: key_name }
      networks:
        - port: { get_resource: dbserver_port }
      metadata:
        stack_name: { get_param: 'OS::stack_name' }
      user_data_format: RAW  # Leave this in. Otherwise the ssh key specified in key_name won't get deployed. I'll buy you a beer if you tell me why that happens.
      user_data:
        str_replace:
          template: { get_param: init_script}
          params:
            deploy_key: { get_param: deploy_key }
            kickstart_repository: { get_param: kickstart_repository }
            kickstart_branch: { get_param: kickstart_branch }
            kickstart_directory: { get_param: kickstart_directory }

  dbserver_port:
    type: OS::Neutron::Port
    properties:
      network_id: { get_resource: mgm_net }

  # for now we create an empty, new volume. We need to format and mount it later in bootstrapping process.
  dbserver_volume:
    type: OS::Cinder::Volume
    properties:
      description: test volume 
      name: test volume
      size: 100 

  dbserver_volume_attach:
    depends_on: [ dbserver, dbserver_volume ]
    type: OS::Cinder::VolumeAttachment
    properties:
      instance_uuid: { get_resource: dbserver }
      volume_id: { get_resource: dbserver_volume }

outputs:
  shopsetup_loadbalancer_public_ip:
    description: Floating IP address of loadbalancer in public network
    value: { get_attr: [ loadbalancer_floating_ip, floating_ip_address ] }


